{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Prático 1\n",
    "\n",
    "## Redes Neurais - 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elaborado por: Carlos Diego Ferreira, João Victor de Oliveira e Luiz Carlos Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória e Visualização de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma breve contextualização do dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset contendo informações acerca da pandemia de SARS-CoV-2 dentro da cidade Manaus, no estado do Amazonas, Brasil.\n",
    "As fontes de dados são originadas dos seguintes sistemas: e-SUS notifica (VE), SIVEP-Gripe e GAL\n",
    "Dataset retirado de https://covid19.manaus.am.gov.br/wp-content/uploads/Manaus.csv\n",
    "\n",
    "Capacidade atual de testagem diária do município: 384 pessoas/dia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrir dataset em formato csv usando pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../config/dataset_covid_manaus.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-2849fe063e4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df = pd.read_csv('../config/dataset_covid_manaus.csv', sep = ';', encoding='latin-1'\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#                  , parse_dates = [10, 12, 14]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 ) \n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Foi feita uma conversão das colunas com datas de strings para o objetos timestamps.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1874\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../config/dataset_covid_manaus.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../config/dataset_covid_manaus.csv', sep = ';', encoding='latin-1'\n",
    "#                  , parse_dates = [10, 12, 14]\n",
    "                ) \n",
    "#Foi feita uma conversão das colunas com datas de strings para o objetos timestamps.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De acordo com o indicado na descrição do projeto, serão mantidos apenas os casos confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_idade</th>\n",
       "      <th>_faixa etária</th>\n",
       "      <th>_sexo</th>\n",
       "      <th>_bairro</th>\n",
       "      <th>_classificacao</th>\n",
       "      <th>_comorb_renal</th>\n",
       "      <th>_comorb_diabetes</th>\n",
       "      <th>_comorb_imuno</th>\n",
       "      <th>_comorb_cardio</th>\n",
       "      <th>_conclusao</th>\n",
       "      <th>...</th>\n",
       "      <th>_distrito</th>\n",
       "      <th>_bairro_mapa</th>\n",
       "      <th>_comorb_respiratoria</th>\n",
       "      <th>_comorb_cromossomica</th>\n",
       "      <th>_comorb_hepatica</th>\n",
       "      <th>_comorb_neurologica</th>\n",
       "      <th>_comorb_hemato</th>\n",
       "      <th>_comorb_obessidade</th>\n",
       "      <th>_origem</th>\n",
       "      <th>_evolução</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>30a - 39a</td>\n",
       "      <td>F</td>\n",
       "      <td>CONJ. CIDADAO 10</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>OESTE</td>\n",
       "      <td>TARUMÃ</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eSUS VE,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>50a - 59a</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eSUS VE,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.0</td>\n",
       "      <td>70a - 79a</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eSUS VE,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>50a - 59a</td>\n",
       "      <td>F</td>\n",
       "      <td>ALEIXO</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SUL</td>\n",
       "      <td>ALEIXO</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eSUS VE,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>50a - 59a</td>\n",
       "      <td>M</td>\n",
       "      <td>PARQUE10</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SUL</td>\n",
       "      <td>PARQUE 10 DE NOVEMBRO</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eSUS VE,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _idade _faixa etária _sexo           _bairro _classificacao _comorb_renal  \\\n",
       "0    37.0     30a - 39a     F  CONJ. CIDADAO 10     Confirmado           Não   \n",
       "1    51.0     50a - 59a     F               NaN     Confirmado           Não   \n",
       "2    74.0     70a - 79a     M               NaN     Confirmado           Não   \n",
       "3    51.0     50a - 59a     F            ALEIXO     Confirmado           Não   \n",
       "4    53.0     50a - 59a     M          PARQUE10     Confirmado           Não   \n",
       "\n",
       "  _comorb_diabetes _comorb_imuno _comorb_cardio _conclusao  ... _distrito  \\\n",
       "0              Não           Não            Não        NaN  ...     OESTE   \n",
       "1              Não           Não            Não        NaN  ...       NaN   \n",
       "2              Não           Não            Não        NaN  ...       NaN   \n",
       "3              Não           Não            Não        NaN  ...       SUL   \n",
       "4              Não           Não            Não        NaN  ...       SUL   \n",
       "\n",
       "            _bairro_mapa _comorb_respiratoria _comorb_cromossomica  \\\n",
       "0                 TARUMÃ                  Não                  Não   \n",
       "1                    NaN                  Não                  Não   \n",
       "2                    NaN                  Não                  Não   \n",
       "3                 ALEIXO                  Não                  Não   \n",
       "4  PARQUE 10 DE NOVEMBRO                  Não                  Não   \n",
       "\n",
       "  _comorb_hepatica _comorb_neurologica _comorb_hemato _comorb_obessidade  \\\n",
       "0              NaN                 NaN            NaN                NaN   \n",
       "1              NaN                 NaN            NaN                NaN   \n",
       "2              NaN                 NaN            NaN                NaN   \n",
       "3              NaN                 NaN            NaN                NaN   \n",
       "4              NaN                 NaN            NaN                NaN   \n",
       "\n",
       "     _origem _evolução  \n",
       "0  eSUS VE,        NaN  \n",
       "1  eSUS VE,        NaN  \n",
       "2  eSUS VE,        NaN  \n",
       "3  eSUS VE,        NaN  \n",
       "4  eSUS VE,        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['_classificacao'] == 'Confirmado'].reset_index(drop=True) #nesse caso foram descartados os casos 'Descartado' e 'Em análise'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição do conteúdo do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantos e quais atributos descrevem cada elemento do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de atributos preditores: 36\n",
      "São eles:\n",
      "_idade\n",
      "_faixa etária\n",
      "_sexo\n",
      "_bairro\n",
      "_classificacao\n",
      "_comorb_renal\n",
      "_comorb_diabetes\n",
      "_comorb_imuno\n",
      "_comorb_cardio\n",
      "_conclusao\n",
      "_dt_notificacao\n",
      "_taxa\n",
      "_dt_evolucao\n",
      "_raca\n",
      "_dt_sintomas\n",
      "_criterio\n",
      "_tipo_teste\n",
      "_sintoma_garganta\n",
      "_sintoma_dispneia\n",
      "_sintoma_febre\n",
      "_sintoma_tosse\n",
      "_sintoma_outros\n",
      "_etnia\n",
      "_profiss_saude\n",
      "_srag\n",
      "_se_notificacao\n",
      "_distrito\n",
      "_bairro_mapa\n",
      "_comorb_respiratoria\n",
      "_comorb_cromossomica\n",
      "_comorb_hepatica\n",
      "_comorb_neurologica\n",
      "_comorb_hemato\n",
      "_comorb_obessidade\n",
      "_origem\n",
      "_evolução\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de atributos preditores: '+str(len(df.columns)))\n",
    "print('São eles:')\n",
    "for c in df.columns:\n",
    "#     print(c[1:]) #para melhor visualização, retirei o '_' presente na primeira posição de todos os atributos\n",
    "    print(c) #para visualizá-los com seus nomes originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantos casos confirmados há em Manaus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36947"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Considerando que apenas os casos confirmados encontram-se no dataset, trata-se apenas do tamanho deste, no entanto, \n",
    "#caso fosse uma requisição de outro aributo que tivesse mais de uma opção, seria da seguinte forma:\n",
    "df['_classificacao'].value_counts()['Confirmado']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qual o período de tempo do dataset (baseando-se na data de notificação):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Obs: dentre os 36947 casos, 4 não possuiam data de notificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_dates = pd.to_datetime(df['_dt_notificacao'].dropna().astype(str), format='%d/%m/%Y')\n",
    "first = np.min(datetime_dates)\n",
    "latest = np.max(datetime_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeira notificação foi em: 30/01/2020\n",
      "Notificação mais recente(retirado no dia 06/08/2020) foi em: 06/08/2020\n"
     ]
    }
   ],
   "source": [
    "print('Primeira notificação foi em: %s/%s/%4d' %(first.strftime('%d'), first.strftime('%m'), first.year))\n",
    "print('Notificação mais recente(retirado no dia 06/08/2020) foi em: %s/%s/%4d' %(latest.strftime('%d'), latest.strftime('%m'), latest.year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conforme especificado no pdf do projeto:\n",
    "\"Para fins da análise considerada no escopo deste projeto, vamos excluir todos os atributos relativos\n",
    "às comorbidades, sintomas, etnia, profissão, outras datas que não a de notificação, origem e outros\n",
    "que não estiverem envolvidos no contexto do trabalho solicitado. Estes atributos serão considerados\n",
    "irrelevantes para fins de simplificação.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E ainda:\n",
    "\"Exclua todas as linhas em que houver dados faltantes para os\n",
    "atributos remanescentes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo os atributos especificados:\n",
    "df = df.drop(['_comorb_renal', '_comorb_diabetes', '_comorb_imuno', '_comorb_cardio', '_taxa', '_dt_evolucao', '_raca',\n",
    "       '_dt_sintomas', '_sintoma_garganta', '_classificacao', \n",
    "       '_sintoma_dispneia', '_sintoma_febre', '_sintoma_tosse',\n",
    "       '_sintoma_outros', '_etnia', '_profiss_saude', '_srag', '_criterio', \n",
    "       '_se_notificacao', '_distrito', '_bairro_mapa', '_comorb_respiratoria',\n",
    "       '_comorb_cromossomica', '_comorb_hepatica', '_comorb_neurologica',\n",
    "       '_comorb_hemato', '_comorb_obessidade', '_origem', '_evolução'], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
